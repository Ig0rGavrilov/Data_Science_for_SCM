{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bc7c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def import_data():\n",
    "    data = pd.read_csv('norway_new_car_sales_by_make.csv')\n",
    "    data['Period'] = data['Year'].astype(str) + '-' + data['Month'].astype(str).str.zfill(2)\n",
    "    df=pd.pivot_table(data=data, values='Quantity', index='Make', columns='Period', aggfunc='sum', fill_value=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcffca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets(df, x_len=12, y_len=1, test_loops=12):\n",
    "    \n",
    "    D = df.values\n",
    "    rows, periods = D.shape\n",
    "    \n",
    "    # Training set creation\n",
    "    loops = periods + 1 - x_len - y_len\n",
    "    train = []\n",
    "    \n",
    "    for col in range(loops):\n",
    "        train.append(D[:,col:col+x_len+y_len])\n",
    "    train = np.vstack(train)\n",
    "    X_train, Y_train = np.split(train,[-y_len], axis=1)\n",
    "    \n",
    "    # Test set creation\n",
    "    \n",
    "    if test_loops>0:\n",
    "        X_train, X_test = np.split(X_train, [-rows*test_loops], axis=0)\n",
    "        Y_train, Y_test = np.split(Y_train, [-rows*test_loops], axis=0)\n",
    "    else:  # No test set: X_test is ised to generate the future forecast\n",
    "        X_test = D[:,-x_len:]\n",
    "        Y_test = np.full((X_test.shape[0],y_len),np.nan)\n",
    "        \n",
    "    # Formatting required for scikit-learn\n",
    "    \n",
    "    if y_len == 1:\n",
    "        Y_train = Y_train.ravel()\n",
    "        Y_test = Y_test.ravel()\n",
    "        \n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aef41926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = import_data()\n",
    "X_train, Y_train, X_test, Y_test = datasets(df, x_len=12, y_len=1, test_loops=12)\n",
    "df.to_excel('demand.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a3f50da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name=''):\n",
    "    df = pd.DataFrame(columns=['MAE', 'RMSE', 'Bias'], index = ['Train', 'Test'])\n",
    "    df.index.name=name\n",
    "    df.loc['Train', 'MAE'] = 100*np.mean(abs(Y_train-Y_train_pred))/np.mean(Y_train)\n",
    "    df.loc['Train', 'RMSE'] = 100*np.sqrt(np.mean((Y_train-Y_train_pred)**2))/np.mean(Y_train)\n",
    "    df.loc['Train', 'Bias'] = 100*np.mean((Y_train-Y_train_pred))/np.mean(Y_train)\n",
    "    df.loc['Test', 'MAE'] = 100*np.mean(abs(Y_test-Y_test_pred))/np.mean(Y_test)\n",
    "    df.loc['Test', 'RMSE'] = 100*np.sqrt(np.mean((Y_test-Y_test_pred)**2))/np.mean(Y_test)\n",
    "    df.loc['Test', 'Bias'] = 100*np.mean((Y_test-Y_test_pred))/np.mean(Y_test)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8ed663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c84877ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             MAE       RMSE      Bias\n",
      "ETR                                  \n",
      "Train  17.818651  43.421932 -0.001547\n",
      "Test   18.856165  46.733273  3.150073\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "ETR = ExtraTreesRegressor(n_jobs=-1, n_estimators=200, min_samples_split=15, min_samples_leaf=4, max_samples=0.95, max_features=4, max_depth=8, bootstrap=True)\n",
    "ETR.fit(X_train, Y_train)\n",
    "\n",
    "Y_train_pred= ETR.predict(X_train)\n",
    "Y_test_pred = ETR.predict(X_test)\n",
    "\n",
    "kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_predict, name = 'ETR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08340112",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc26c6e0",
   "metadata": {},
   "source": [
    "#### Using random search chapter 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed376041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=ExtraTreesRegressor(n_estimators=30, n_jobs=1),\n",
       "                   n_iter=400, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True],\n",
       "                                        'max_depth': [6, 7, 8, 9, 10, 11, 12,\n",
       "                                                      None],\n",
       "                                        'max_features': range(5, 13),\n",
       "                                        'max_samples': [0.7, 0.8, 0.9, 0.95, 1],\n",
       "                                        'min_samples_leaf': range(2, 13),\n",
       "                                        'min_samples_split': range(7, 16)},\n",
       "                   scoring='neg_mean_absolute_error', verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "max_depth = list(range(6,13)) + [None]\n",
    "min_samples_split = range(7,16)\n",
    "min_samples_leaf = range(2,13)\n",
    "max_features = range(5,13)\n",
    "bootstrap = [True]\n",
    "max_samples = [0.7, 0.8, 0.9, 0.95, 1]\n",
    "\n",
    "param_dist = {'max_depth': max_depth, 'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'max_features': max_features, 'bootstrap': bootstrap, 'max_samples': max_samples}\n",
    "\n",
    "ETR = ExtraTreesRegressor(n_jobs=1, n_estimators=30)\n",
    "ETR_cv = RandomizedSearchCV(ETR, param_dist, cv=5, verbose=2, n_jobs=-1, n_iter=400, scoring='neg_mean_absolute_error')\n",
    "ETR_cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4249ff3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Forest Parameters: {'min_samples_split': 14, 'min_samples_leaf': 2, 'max_samples': 0.8, 'max_features': 12, 'max_depth': 8, 'bootstrap': True}\n",
      "\n",
      "                     MAE       RMSE      Bias\n",
      "ETR optimized                                \n",
      "Train          15.624624  38.836382  0.161255\n",
      "Test           18.856165  46.733273  3.150073\n"
     ]
    }
   ],
   "source": [
    "print('Tuned Forest Parameters:', ETR_cv.best_params_)\n",
    "print()\n",
    "Y_train_pred= ETR_cv.predict(X_train)\n",
    "Y_test_pred = ETR_cv.predict(X_test)\n",
    "kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_predict, name = 'ETR optimized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0e3308",
   "metadata": {},
   "source": [
    "#### Using ETR with 200 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c13518a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               MAE       RMSE      Bias\n",
      "ETRx200                                \n",
      "Train    15.521089  38.443071  0.060833\n",
      "Test     18.856165  46.733273  3.150073\n"
     ]
    }
   ],
   "source": [
    "ETR = ExtraTreesRegressor(n_estimators=200, n_jobs=-1, **ETR_cv.best_params_).fit(X_train, Y_train)\n",
    "\n",
    "Y_train_pred= ETR.predict(X_train)\n",
    "Y_test_pred = ETR.predict(X_test)\n",
    "\n",
    "kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_predict, name = 'ETRx200')\n",
    "\n",
    "## **ETR_cv is using best params from dictionary line 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88524344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
